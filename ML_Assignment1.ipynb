{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. What is a parameter?\n",
        "A parameter is a variable that defines certain characteristics of a model or a function. In machine learning, parameters are the internal variables that are learned from the training data, such as the weights in linear regression or the filters in a neural network.\n",
        "\n",
        "#2. What is correlation?\n",
        "Correlation measures the statistical relationship between two variables. It indicates how one variable changes with respect to another. If one variable increases as the other increases, the correlation is positive. If one decreases as the other increases, the correlation is negative.\n",
        "\n",
        "#3. What does negative correlation mean?\n",
        " Negative correlation means that as one variable increases, the other decreases, and vice versa. For example, the relationship between outdoor temperature and heating bills would likely show negative correlation.\n",
        "\n",
        "#4. Define Machine Learning. What are the main components in Machine Learning?\n",
        " Machine learning is a branch of artificial intelligence (AI) that allows systems to learn from data and improve over time without being explicitly programmed. The main components of machine learning are:\n",
        "\n",
        "Data: The information used to train the model.\n",
        "Model: The mathematical structure or algorithm used to make predictions.\n",
        "Algorithm: The method used to train the model on data.\n",
        "Evaluation: The process of testing the model's performance.\n",
        "How does loss value help in determining whether the model is good or not? Loss value indicates how well a model's predictions match the true outcomes. A lower loss means better predictions. Monitoring the loss value during training helps determine whether the model is improving and how well it generalizes.\n",
        "\n",
        "#5. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables: These are variables that can take any value within a range, such as height, weight, or temperature.\n",
        "Categorical variables: These are variables that represent categories or groups, like gender, color, or type of product.\n",
        "\n",
        "#6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "Categorical variables can be handled using techniques such as:\n",
        "\n",
        "One-hot encoding: Creates binary columns for each category.\n",
        "Label encoding: Converts categories into numerical labels.\n",
        "Ordinal encoding: For ordinal variables, assigns integers based on the order.\n",
        "\n",
        "#7. What do you mean by training and testing a dataset?\n",
        "\n",
        "Training dataset: The data used to train the machine learning model, allowing it to learn patterns.\n",
        "Testing dataset: The data used to evaluate the model's performance after training.\n",
        "\n",
        "#8. What is sklearn.preprocessing?\n",
        "sklearn.preprocessing is a module in the Scikit-learn library that provides functions to preprocess data, such as scaling, normalization, encoding categorical features, and imputing missing values.\n",
        "\n",
        "#9. What is a Test set?\n",
        "A test set is a subset of the dataset that is used to evaluate the performance of a trained machine learning model. It is separate from the training set and is used to assess how well the model generalizes to new data.\n"
      ],
      "metadata": {
        "id": "9xRDP9yJSGiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "The typical approach includes:\n",
        "\n",
        "-->Data collection and understanding\n",
        "\n",
        "-->Data cleaning and preprocessing\n",
        "\n",
        "-->Feature engineering\n",
        "\n",
        "-->Model selection\n",
        "\n",
        "-->Model training and evaluation\n",
        "\n",
        "-->Hyperparameter tuning\n",
        "\n",
        "-->Model deployment and monitoring\n",
        "\n",
        "\n",
        " In Python, the data can be split using train_test_split from Scikit-learn:"
      ],
      "metadata": {
        "id": "8UqW-oLcUAO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np  # Importing numpy for creating sample data\n",
        "\n",
        "\n",
        "# Create sample data for demonstration\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])  # Features\n",
        "y = np.array([0, 1, 0, 1])  # Target variable\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "PCFezW5IUrXU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This splits the data into 80% training and 20% testing."
      ],
      "metadata": {
        "id": "TfcfFsVBUyJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. Why do we have to perform EDA before fitting a model to the data?\n",
        "Exploratory Data Analysis (EDA) helps to understand the dataset's characteristics, identify patterns, detect outliers, and discover relationships between variables. It also assists in making decisions about how to preprocess data and which models might work best.\n",
        "\n",
        "#12. What is correlation?\n",
        " As answered above, correlation measures the relationship between two variables, indicating whether they increase or decrease together.\n",
        "\n",
        "#13. What does negative correlation mean?\n",
        " Negative correlation means that when one variable increases, the other decreases, and vice versa.\n",
        "\n",
        "#14. How can you find correlation between variables in Python?\n",
        "You can calculate correlation using pandas' corr() method:\n",
        "\n"
      ],
      "metadata": {
        "id": "TjajjVinU1GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "correlation_matrix = df.corr()\n"
      ],
      "metadata": {
        "id": "JUzfG-pQV_QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. What is causation? Explain the difference between correlation and causation with an example.\n",
        " Causation refers to a cause-and-effect relationship between two variables, meaning one variable directly influences the other. Example: Smoking (cause) leads to lung cancer (effect).\n",
        "Difference: Correlation does not imply causation. Two variables may be correlated due to a third variable or random chance, but that does not mean one causes the other.\n",
        "\n",
        "#16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        " An optimizer adjusts the parameters of a machine learning model to minimize the loss function. Common types include:\n",
        "\n",
        "Gradient Descent: Iteratively adjusts parameters to minimize the loss function.\n",
        "Stochastic Gradient Descent (SGD): A variation of gradient descent that uses one training example at a time.\n",
        "Adam: Combines momentum and adaptive learning rates, often preferred for deep learning models.\n",
        "\n",
        "#17. What is sklearn.linear_model?\n",
        "sklearn.linear_model is a module in Scikit-learn that provides various linear models for regression and classification, such as LinearRegression, LogisticRegression, and Ridge.\n",
        "\n",
        "#18. What does model.fit() do? What arguments must be given?\n",
        "The model.fit() method trains the model using the provided training data. The arguments required are:\n",
        "\n",
        "X: Features (input data)\n",
        "y: Target (output or labels)\n",
        "\n",
        "#19. What does model.predict() do? What arguments must be given?\n",
        "The model.predict() method is used to make predictions based on the input features after the model is trained. The argument required is the feature data X for which predictions need to be made.\n",
        "\n",
        "#20. What are continuous and categorical variables?\n",
        "Continuous variables are numerical and can take any value in a range.\n",
        "Categorical variables are non-numerical and represent categories or groups.\n",
        "\n",
        "#21. What is feature scaling? How does it help in Machine Learning?\n",
        "Feature scaling is the process of standardizing or normalizing feature values to a consistent scale. It helps models converge faster and prevents models from being biased towards features with larger values, especially in algorithms like gradient descent.\n",
        "\n",
        "#22. How do we perform scaling in Python?\n",
        "Scaling can be done using Scikit-learn's StandardScaler or MinMaxScaler:"
      ],
      "metadata": {
        "id": "PZsWZwPaWAWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "Et0jlOpMXL3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#23. What is sklearn.preprocessing?\n",
        "As described earlier, sklearn.preprocessing is a module that provides various methods to preprocess data, including scaling, encoding, and handling missing values.\n",
        "\n",
        "#24. How do we split data for model fitting (training and testing) in Python?\n",
        " This question was answered earlier with the use of train_test_split from Scikit-learn. Refer question 10th answer.\n",
        "\n",
        "#25. Explain data encoding?\n",
        "Data encoding is the process of converting categorical data into a numerical format so that machine learning algorithms can process it. Techniques include one-hot encoding, label encoding, and ordinal encoding.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gFfrZFBaX7Iz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkGby8UjX6mO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}