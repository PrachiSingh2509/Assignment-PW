{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi6hgyaTx4rO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What does R-squared represent in a regression model?\n",
        "Ans. R-squared, or the coefficient of determination, represents the proportion of the variance in the dependent variable that is explained by the independent variables in the model. Its value ranges from 0 to 1:\n",
        "\n",
        "0: The model explains none of the variability in the data.\n",
        "1: The model explains all the variability in the data.\n",
        "\n",
        "2. What are the assumptions of linear regression?\n",
        "Ans. Linearity: The relationship between the independent and dependent variables is linear.\n",
        "Independence: Observations are independent of each other.\n",
        "Homoscedasticity: The variance of residuals is constant across all levels of the independent variable(s).\n",
        "Normality of residuals: Residuals are normally distributed.\n",
        "No multicollinearity: Independent variables are not highly correlated with each other.\n",
        "\n",
        "3. What is the difference between R-squared and Adjusted R-squared?\n",
        "Ans. R-squared: Measures the proportion of variance explained by the model but increases with the addition of variables, regardless of their significance.\n",
        "Adjusted R-squared: Adjusts R-squared to account for the number of predictors, penalizing the inclusion of irrelevant variables. It provides a more accurate measure of model performance.\n",
        "\n",
        "4. Why do we use Mean Squared Error (MSE)?\n",
        "Ans. MSE is used to measure the average squared difference between the predicted and actual values. It penalizes larger errors more than smaller ones, making it sensitive to outliers and suitable for optimization in regression models.\n",
        "\n",
        "5. What does an Adjusted R-squared value of 0.85 indicate?\n",
        "Ans. An Adjusted R-squared of 0.85 indicates that 85% of the variance in the dependent variable is explained by the independent variables, accounting for the number of predictors. It suggests a good fit but may still include some bias if assumptions are violated.\n",
        "\n",
        "6. How do we check for normality of residuals in linear regression?\n",
        "Ans. Histogram: Plot the residuals to see if they follow a bell-shaped curve.\n",
        "Q-Q Plot: Compare the quantiles of residuals against a normal distribution.\n",
        "Statistical Tests: Use the Shapiro-Wilk or Kolmogorov-Smirnov test for normality.\n",
        "\n",
        "7. What is multicollinearity, and how does it impact regression?\n",
        "Ans. Definition: Multicollinearity occurs when independent variables are highly correlated.\n",
        "Impact:\n",
        "Inflates standard errors of coefficients.\n",
        "Reduces the reliability of coefficient estimates.\n",
        "Makes it hard to determine the effect of each predictor.\n",
        "\n",
        "8. What is Mean Absolute Error (MAE)?\n",
        "Ans. MAE measures the average absolute difference between predicted and actual values. It gives equal weight to all errors, making it less sensitive to outliers compared to MSE.\n",
        "\n",
        "9. What are the benefits of using an ML pipeline?\n",
        "Ans. Consistency: Ensures reproducible workflows.\n",
        "Modularity: Allows for step-by-step transformations (e.g., preprocessing, feature selection, modeling).\n",
        "Efficiency: Automates repetitive tasks.\n",
        "Scalability: Easily adapts to new data or model updates.\n",
        "\n",
        "10. Why is RMSE considered more interpretable than MSE?\n",
        "Ans. RMSE is the square root of MSE, making it interpretable in the same unit as the dependent variable. It provides a direct measure of average prediction error.\n",
        "\n",
        "11. What is pickling in Python, and how is it useful in ML?\n",
        "Ans. Pickling serializes Python objects (e.g., ML models) into a binary format for storage. It's useful for saving trained models and reusing them without retraining.\n",
        "\n",
        "12. What does a high R-squared value mean?\n",
        "Ans. A high R-squared value indicates that the model explains a large portion of the variance in the dependent variable. However, it does not guarantee model quality, as it may overfit the data.\n",
        "\n",
        "13. What happens if linear regression assumptions are violated?\n",
        "Ans. Linearity: Leads to biased predictions.\n",
        "Homoscedasticity: Reduces model efficiency and increases the risk of Type I errors.\n",
        "Normality: Affects confidence intervals and hypothesis tests.\n",
        "Independence: Results in unreliable standard errors and p-values.\n",
        "Multicollinearity: Causes unstable coefficients.\n",
        "\n",
        "14. How can we address multicollinearity in regression?\n",
        "Ans. Remove highly correlated predictors.\n",
        "Use regularization techniques like Ridge or Lasso regression.\n",
        "Perform Principal Component Analysis (PCA) to reduce dimensionality.\n",
        "\n",
        "15. How can feature selection improve model performance in regression analysis?\n",
        "Ans. Feature selection reduces overfitting, improves interpretability, and enhances generalization by keeping only the most relevant predictors.\n",
        "\n",
        "16. How is Adjusted R-squared calculated?\n",
        "Ans. Adjusted R-squared formula:\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkIAAAEMCAYAAAAoHdmBAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAADPJSURBVHhe7d0NcBzVgSfwP1dUoasgiQ1ryxBAe16LyRokKxvL9rJgVdYwXtdayjoeWTa4lESKlWWN8C22dwmzgmBlLgTDLpbM3iLQBisOWB5tHEs5tB5IYMQVQXIWJPnQ0Xah8uSD9VDhzlLh8lDxVd973W9muntm9P3d/19VW9Mf0/26W3b//d7r7qt0AUREREQu9J/UTyIiIiLXYRAiIiIi12IQIiIiItdiECIiIiLXYhAiIiIi15q7INRVg5ycGoTUqDlegqYhNT6fOMtKYxvvMTOWy5m/514aakLJfC4fERFN2vQEIeNCkYOSQxE1wW1CqDEu5vbBvcdjnOTvTeUAAn0jGBk5jbrlajoREdEsmZYgFHrCD6z0QHu5A5O+9G9qmd6L4RzU4lS0yQu6GvoCQH0hw9BotD5oKIKHAYiIiObINAShENqOeVD1UgAVg34c6FKT3W55HdobRDh8T1MTiIiIaL6ZehDqakNwZRXKl3vxqLjwB0+kr4MJ1VqbjdLU1NhqcCJoWpeDGkeoihwqQc66Jkutk7lccr1mPw5jW5VBMT8IX8r2HM1YtvWZxizrOE0kBNm36dh31fQYn1dyKGTsd7K2Se5Tah8WY521ltI71uPc9/jy8bLY15/5e9JEj5mxvPUcWdZpnOfEusRg3QchbTnj/Xi6rPuoypHoh2SZFifnpeyPub/O3z8r+/7alzXLP/nfGyIimj1TDEIiiDwehGdHOfLFWH5ZFTzH/GkvyL6BAM4kmo2K4TcuglMTqi2Ev6g90Rx1pqHImO5tFuNtFeJTBdqNeS3wGnPkBc4HWJqw2ov8KLRcCKetrOIC6zvmQeBhc8ujkRdO2zaNsivyAl/sR5GlzIH3fPAPqvkTEHqiD4H4NkbOIACx746QgWM+tG0xlzm9R57VmTlmKefo7Trjd0iuq7C+SJ03OYhyDvhSw0pKOSUN/sehviu+t1KFrMeLVdnUNOc+T5Q4J223nVHlE4PYj2AlO1MTES1EUwtCQx1oHfSgqkxdiJaXo2qlhtZOyyVLXDT8MhC8ZF7oDMvrcNp6sZ+UCLQBwHObR42LILanZdQ+RpFDfgS3t6Nlk5ogeB8OwDPYig55EZtiWYOVllqCE5XiIjm+Pk9GzVGRJ7nNTS2JMsr+V5qzzM3ygq5GJsDbHA+EUj7Kd4hjN6DZA8bKAB61bGumj5lNfF199nLWvWTZXpyjnCZrOcT3HpNlSDPtWNvUamvE/rUkwpewqVLEOQ19qgIwf89pce6t+0BERPPVlIJQpLNVXKQDlou9eXG1dZqWHWKNpjM1Pm3Mi5pWXzjuZggjcBzzJcOKHIpF0FDzp1rWRGdpGQLEdtI27Vm3rWomjGBhlMtZq2CGvYot03dJtTbpFNanabqzBjJhpo+ZTaZ1qYAdDxoGRzkzm6HO2CK0JZvgfJh6/SYREc2FKQShEA7IC6njImlcXGer07Rxp5lsEhtI0xcoPU+DpUkjMUzzrduiXGdkf6nH7c05Zk2BZbvNKuDIGhQ53lYEf7HcjxloZlEXbh+sTYnJ2rTRzMoxW0CMMFnciirjtn85tGMS9V9ERDQPTD4IyU7SiT441sFstrF1mnY2awiRswPqU2YDZ22NNhk7H5sBQ16MgmgbJYDJZrQxb/GfZFmd8veYd9H5JnL7vBHs5PGzNy+mdkDX0JfSR8hRY6Jqk+KM2ruVAZyJh69xms1jBk9xahOYpJpgi8eX2yZuUN7GbzGkIXPp5V2SsvaPzz0iIloMJh2EQieCwPbKNP0gHP0wNj1qXNj991pqR4aa4EvXLJOgmtjqDyRreIzOx+qzIYKmWkcHWit5URWXM81yUTU6c6eEkxBq4p1nJ1XWTLxoaZNNd74xa3dCtZlqsuLH0t7MFqp1NsV4UbldBCZLDVTkkL1Ddf6tRfYL/jj3a1aP2fI6BLaLdRVbj4c4z/fKflLWJthpZPTvCcKf2D+1PTWWSgQyEfStId15PnjXGBHRwjG5ICQudH75v+JMfVdsFxdxMX/7jHmHUrwJ7V6gfYzOtPl72sUFNn77uxhOVKY25QxY1qnubEp06k1cVOU8dVGSTVDqQYfxprycHD+KE3d2Ta6sGaULCWlZ9jOnEK07ziTvhJK1RGL71o7YbVtSO0t7m9uNGqh4uWUTWLsIRwliPe3bLdsR+xUYT9PYLB8zeTeZrZzqeCSaEaddPLDG90/8Hr00WlOX2N+X7MejbQubxoiIFqqrdEF9nlvyeS7yNmd1GzWNRj4/yRGYiIiIaMKmdNfYdJpUnxIiIiKiKZgnQci8A63iMdYGERER0eyZ2yA0FH8Wiw8DDWdsD+0jIiIimmnzp48QERER0SybN32EiIiIiGYbgxARERG5FoMQERERuRaDEBEREbkWgxARERG5FoMQERERuRaDEBEREbkWgxARERG5FoMQERERuRaDEBEREbkWgxARERG5FoMQERERuRaDEBEREbkWgxARERG5FoMQERERuRaDEBEREbkWgxARERG5FoMQERERuRaDEBEREbkWgxAREdFi9nEIB1/sVyPkxCBERES0yMTOhtHxQgNqNhdi6X/xoeGtqJpDTgxCREREi9H1a/Hgc4+iTI1SegxCREREi0zWraUo3+LFqs/lqimUCYMQERHRdPi4H6ETYWiX1HhsGFp3Bzpe7Uc0Po3mHQYhIiKiqboUwgO1P8DwOw0o+fwDCL7egLKNfoQ/Bj4NPYCCm8vQ+hu1LM0rDEJERERTFD3ajKw9T6HijnxguBUPvbwWR8OHUbulHBX3b4PnShjhAbUwzSsMQkS04MV+048Qmx9ozsTQf96DbXcA2qBMO14EDnqR6J0TjSAifvznq83RjGLDiEaj4xs+jqkv0VRdpQvqMxHRAjOM0IM70VG0C95re9D4101Aw2m8ttuj5tPiE8PwYA/Cv12G0jUe5GapyfNCFK2bC/AADuPcT6qQp6ZqgUKUfM+Dlv9oR8Vn1MQ0oq8eREOnjEzjsQa7GquwSo1lFkJNjg/B7e0YafaqaWTFIEREC9dgA0qqz+NvX2pBxXJxiWz3YWn1pzh8rhNV8asQITYcQ9b8SgyTc0VD01cbcLFsG1ZFj2Pv4z3Y+MNf4PAms+5lzvfzSgdqPrsT3XvfxLnH4hFFQ8PtJTi4qgUf/bACs186BqGxsGmMiBYwcVkZDKHvYzX2x6XwIIxe9sVI0J69G5tfHG8tw/wW+3EDmn+7ChvLylG+5yja9wCtIhj1qvmRFzfj7kOaGpsDp7vRKX5svMNSTzN4HMd/CZRvKUPWlV7sq23FsJpF8wODEBEtXCv34/TIrxAoMUdj74TF/7/LUXqHOe52w1012Nz9TfzrnkXSVHiNCDs/78b7n5ijq9asFye9Bz0iaEiePf+Kb761GTVdcxM1tLfCiMFr+/2LvNqBCCqw7S+zED3agAvebcm+Q7PpCvsUZcIgRDQTLvWi6VtBo4PkZMQ+jmJ4kXT8jQ1HER2ehX+Er/Tj4Ld7UP4vT4/aD8M1hoOoqRzAg9+tmJsL7wzIKjuKkZFks2d/bzdwixfeW8xxiD2t+If9iFTWIDjrWSiGgXc04EvlWG/5/ctfXw4PevF8bRl879ThWd8sNY697kfBHxVgqWwWk+PtO5GztEBM86FZBUdSZB8hIppel4P36dnZS/S9b6kJ43T++Q3ie9nGsPqZ82qqoh3Xq7dV68c1NT7f/WyvvkTtS/auU2piem88vEK/6ffUssawRF/x+RXm93/vJv3ObQf0kx9cVkunc1E/df+d+n3BC2p8Ll3W3/9Bo35qjovSs+8mPfve46I0mV1+74jeGJrDgoYf0W9fscRy3rP1JSvivwvid2D9Vv3Aj86n34eLx/Wtv3enfuCd1Llv/M0SfcnfvKHGZtEnF/WL6Qp7+aJ+4bejnQmaSwxCRNPusn58m/pHfV+PmjYBF4/oW8V3nUHo1P3qYnH/6KFiSvqP6E9O54Xxdz36IytEmccIQnEnvy73cYW4uKkJ0uUL+hvfvtPY9w2H31cTrS7qPd/ZrR/ovWiO9p/UT0bMj7Pngt73o+N648Nb9TtvkvuwWm/8QM2aC58c1++TQTysxi0uvHNSP/7MI/rW9SIopfk9mwvm77bjvIu/R+e/v9UIw3c+4zjvv3tfb/RuSJ5zp7dkCN+gP/drNU40CjaNEU23S51oey8f+eJj7MhxhK+Yk8ctd1napgyvvxOBv3sKrzXM3J0f0XeCOD44jc1YV+dh2fXq8zhkGc9ZuQ7XWQ9AVh5KHzuM/XlA77d8aBhU0xXt0EM4uWY/am+JIToYRvPhEC5eo2bOqmuQvymAww/MfX+caLAVHSiDN0NfqWtu8SLwzIOYHz2HNPQbvZ03Yu0XjAlKFvK/Vmu8MLS/vgkhcyJwJYrgQ01Y9i+vob4kF9FXO9Dr/JX9k22oyupF56t84zqNjUGIaJrFutqg7WjBo5vkSCs63zKnT9nnSlHnr8WaCQSLiRlGd1dYfZ5vRDgy9juC8JuWi9tpP+6uD6JpayEKCgpQsK4M+44By2b91vk8rNpSjvL1Hlw353epx8zzuL4Uq9I8wC/vC6KcW0rhmS+300d70H1W/NxUivXmlKSz/TBuAMzKEr8B0jBCf/sI/u9f1WP91VFE3g2h+cUemZkcirD2S0C4q1scDaLRMQgRTasYOoMatm1Zg7IKWXMTQ+uPxwoXMUTFP+gdJzoQHhxO/w/3JfnE2Qj6xf9+O96NB4EYhuUTZgfD4rv9SEz9WD55VkNYrK/f8W6j2Fmx7AtNaDoWEvPEMt3x7twxaM/txENd4uNF9eTaaGpZYkNhBA/50fCCKOtQ+kuMsQ2x7ZAoZ2yitWEZXcRF4xb5fJTeZUk5JQH8amQEI7bhMNz9tJQB9LwuAk/JqsQD/ea1d8KQf0NKN61PyTNasBXyZvhVj9VhjfgZPboTvheC2LdOhF4RfAtLfTj462Vp9jMLt64UU0Ug7FZTiDJhECKaTkaz2DZsWyn+Kd5UaVyQY0c7MzePDYexr3gp7vxODz6Vo289iYrN/sRzUeKiYvo3Npbgrq07sfO/96upGtpq7kbhujLs/GojzKlRdAd8uLOwBGVf3YlGy/N0er9VgHt+IC4qZaJ8d1yD7r++G2VHzWeu9L+4D01vXTTKEHm1EQ2BBjGcNC5CpmH0Bu7GLV8J4pp7HkTVrRE8VboUdz9reWbLFQ2tX74ZS+8N4oIYjWnHsfsvd6J5yJw9aVdi6H/6ARyM5qK0sR314tjSKH7Zgx6RUZf9vlmHMt/1/kw+eScPa1ZZ4ow455oIPZufjsHb8Bp+sls2NIuldnY6Qq8YwnVGM7TTsvzPiz/7ofEOKRqL6itERNPgcnCrfvt34h07452m03dalR0+n1wr5m87rtu6fGboLK3rffqBNB2P339qtdhGtW6b+kq10RG2+hU1Lubuzl6tP2m94+zCEX2zdV0fNOqrM3SevSzWtyT7dv3Ae2qCcOGf5R1um/UjRt/qi/rJry/Rs287oPf9zphtmmBn6VO75PHK1les36Bv8Iph/QpjPPtPH9F7LkzXXTd9+pN/usK4K228w51P9Knvju38M/J8zGFnaXUek+c+g1HO9+w5rzfKvwPZK/TV8nzL4YtmJ+7b7z+pv/+JWmwyjL8Djt95ojRYI0Q0beLNYvEuqFmjN4+9+qTR8ddbUWbvHJ2hs3Syn4yd2cF4LNchK0tDw7adaDoWhiabvfK24ejBlF4ZaURx/NkgYlkbsdFSG5P3pY3GU5zD74iRoVY0tMeQV1Fu75cywc7SJg8e/P5reO2UGMLn8NHb9Vg10ISt9d3T9ETeVdj/P8/h3P8e//Dm3439RqfJMp6zZH2Z5ijDuJ4tpfVZavKm0Uy8EDQaRkh2ft/03/CmPN9y+MWvcPoxDyJHd+P5KT8hXMP7H6iPRBnwXWNE0+VSEL4batDzubxkX4cr8uIhLgpZtej88CmUWkJC5FAJCus1VLSNoEV2rE4w3w000HAGp/dYK/0jaFpXCH+R/Z1B5nqK0D7Skuwb01WDnMqgbd3D3ftw5+bm5EMe87w4/D/aUXWrGh9qQkmxH0jZrnpXUdYqlG9fpTqtJq35xmFU/cbcnmecZc4kVJsD3zEPAn2nUbdcTRR69y/F3c/F0hyr+cc8H0jZh/SiCH2vAR2OvlwZ/fEuHP7aGKEszblPK+P5Tm9GXgiqyrrqu2fwpmr+MqiyaTvF780/jf17k9Z4j4OQk5OjPtFEyKbJRcGoFyKiKbM3i8Vlbh4zm1DSNWGc0qvTNlmoZgRHM5O5nrGaxpTLF/X3wyf1576zVV8tH1p30169J96U5Wgquay9ofcZz2Hp0fcuEcuuOKBnbCBS2xtvmTMxm8ZSm5Xix2r1U+meIzRxl397Qb9wYQJD2qfkpTfnTWPvHNBXpDv3TvOgaaxnn3yYovP5QebfJXm+V3x7/E2SKdTv5O6QGifKgE1jRNMiiuMvWpvF4jI3j+WvKTVqjj6KzsCzTlI6Z4dQs64JkaxceNaXo9bfjtM/3Y/84XDiPU1O0a59qrP1GpTtFCWN9uOss2nmbBhhWZvxx6UoFT8iv57Z57Zo701Ho88wIu/0oOetCQxDC+g1mbnXGbV2w5fG2Tw1ZzSEX5dldD4/CBjoMe/1uu66KXT4Nv4OeOD5Q2OMKCMGIaJpEBtsRVP3KqxK0xSS8e6xP9mPp9YD4X9uhWaZPnyizXiD9cWLF80JY8jKXSb+PGu5O2YYHSfkGgTr9gab0fqu+iwtzUMeiuCJv6cpb5lx9018uxcvLsMfqNaK0r1PiaATwoEnei231A8j+Pjz+Oha8TGvCvXfzEXsyHPosGSG2OBxtMo+IMMZHgvgEL/d3nnbfd7nVEHe7DfvjrvSgZraxCP2JkiEwXvks3QmMHxh4jeiT9+jAybolnxxVkUo/c04Q+lcvYzzN2GcSvv8oBgiH9rLpAXuwr6fq5FxigzJFJ8/B8+UogVH1QwR0aS8YTYbZSeH3T9Ts4Tzz29N8w6tR8S3lMvv6899ZYW+5Itb9d11u/Xqr2zQ75OvP4gvf5Nl2UzNTJ/06I98MVu/6c+q1Tru0xt/9KTR7CHXsaT8OfHNU3r1TRv0zX96u77h67vFctX6hlV36o+E7a8oeP+wvBPsdn1r3VZ9w/2n7Hez/fqkvltsJ1uVdet6x/d/d1E/9fBqfcmKDXq1mL972wZ9w74nze/IsizZrD+X4dUX8l1jK4xXU8QHeZy2JpeXr1T4Mzn9Jv2+59/QT31b7Mv358N7xeLOG+fRvg/inMi7zh6e7Xdejd4cKX8nV3zevDMrMdwk746z/q7NoN4D+mrH9uX7xXa/kmx+vPhKtX6TnL7tiP5GaK++4StH9ImebeO1HV98Up+exlRazNhZmmg+kA9M/ATIvT4XWVfLByUOA9fmIdf2FvXROx7Lu4+GY1nIzRPrEP/LH/5YrCNXrMPouR1D7FIWssT6bMsZ33SQZYldg7zr085Nft8oq5poJe8uGo4hS23beJP+1bnIm/KTjMU+DfYgrIn9un4VvOvz05efzM7lP67Dm+fqx+6wPE/FhjX0/EzD8LX5KP3SKuSO6+7IOA0HV5fg4Jdew0cH5aMYaapkrffzv9mIunsWXxUbgxDRfPbuQdy1qx+7XjqKqltDeCDHh+Pf5D/uNIaf78PSjWHUj+vOtUUo2oqygn3w/OQjo/mZJif6bge6u3vQ9qNWhN4dTnNX6OLAPkJE81jkrQ70n+1AsDcqQlEPwuL/9/W7GIJoDH+yC3W3aDjp0peORn/civAtddjFEDRl8+sFvTODQYhoHsuveQFPla3CxR/ch5KHz6Pupz9BXfy5P0QZebD/YAUGmprRP1edtufKlX40Nw2g4uD+RX3xng3z7gW9M4RBiGg+y/Kg9odvGk/dPX2qBbUl6Z85TeSUtekf8MKaZvz9UXfVCkWP/j2a17yAf9g0wYt3LILwiRD65QNQpSvxlyGHoQ3P9p11MUS61YuL1bhRllf7ES8eTR8GISKiRSkX5f/Ygvzv3YcmeZu6Gww14b7v5aPlH8szvKYmkwia7vNj4KM2+AruQdPrQdRs+AaaNZE6fvk87r65EP4J3r4/FdEXvwH/6U8Rur8AJQ81wb+5Ao3/LsoyeBCrC2oQWkCPtVoIGISIiBarXC8Ov12PWGd4mt7TNp8NI3wihvq3D8M70YrT7iaEvU+j7p5iXId++L99AX/706Oo316O8j1V8MpXofSO9/UiU9WLg9/3oH7vehT9vohowT6sPdKJwDdkWerxYF4QO7/Tq5al6cAgRES0mOWWYv/e0gnWkCxEuSjdux+lk9hR7V2gfHMe8J58YW0e6p6qgyd+u370Aj4SP8Z8ubF8ZIXz5bMZh1EeMPrLPsTKt8FzpR/hbrHd7d9EeeLFxTH5dArEenuS7wx0kI+rSL/N1GHWW/zmKd4+T0REJBjPXzpShdc+egrxezNj7TuxtLoH+8PnUO94FYjNQCseeGG8NTX5KPfvh3e0R/K824CC0oNYb31prPFYgAcQ9h3FyL+Uq4lW/Wh98HmMuxRl9dg/nucCTfAFvQsNgxAREZF6CGPDH7bgo7YK9bDOGIL3LUVN/36c/l/1s3oXWuTZu1D4rTy0/Ec7KtSDVWPtPhHKQihtPIfOr83igw0XeRBi0xgREVG0B91ngVXr1ySfWH6pEyc7gfwd20QIiqL1q/5x17ZMTQy93f3AylKsSTxdPobOEyEgtwp1FYvv6c5ziUGIiIioN4ww8uC9w1Lj0f1v6BARqKrCA/z8IFpvrUo0mc2oK934ty7x85OLyb5E7x7Egc48VDUH4LW9emcWzdULemcYgxAREbmeNtAL5G7DRms/oDv+HOVXR9AR8OGuJ/Lx7N/NUuPYmR50ix+rPheGb2MNHqi+GwX39qP2p7/A4U2z1+098oIPBX90M3KK/dDEuPZ4CXJuLhDT/CI0Lh7sI0RERBQbxvD/y3W86FgwXmD8Ka7J9JLiGRA5VILC+mU4fK4TVdeO/hJkmjrWCBEREWWlCUHS1VnIncUQZPQPeksDVnpRKrsCfSaXIWiGMQgRERHNB7L26ZfH0Sb7B3mWIWu05w3RtGHTGBER0XzgfBbRZ0qx/7sVWHw3rM8vDEJERETkWmwaIyIiItdiECIiIiLXYhAiIiIi12IQIiIiItdiECIiIiLXYhAiIiIi12IQIiIiItdiECIiIiLXYhAiIiIi12IQIiIiItdiECIiIiLXYhAiIiIi12IQIiIiItdiECIiIiLXYhAiIiIi12IQIiIiItdiECIiIiLXYhAiIiIi12IQIiIiItdiECIiIiLXYhAiIiIi12IQIiIiItdiECIiIiLXmpsgNNSEkpwSNA2pcSIiIqI5MLkgZASZHNR0qXGLUG0OctY1IaLGE7pqkMPwQ0RERPPI5ILQ8nJUrQQGzjrjTghtx8SPwVZ0OAJP5OwAsLIK5cvVBCIiIqI5NsmmsXyU7/BAe7nDXvPT1YYgPPCs1NDaaZ0TQcfLGjw7ysU3iYiIiOaHSfcRyr+1KKXmx6j12R5AQMzS3tPUVGGoA62DHlSVOWNQCDU5OchRQ8mh1Bom63x7k1sETevkd0LGTzk/2VQ3yvdGadYjIiIid5l8Z+lNlaiAhr5E3jFrfSq2eOHdUgEcaxNxRNH6xJJF8NiaxTT4i9tQOTKCETm0ibXV+yx9iGSY8QFtar4Y2ov8KHT0P9Lq/cBL5vyWTXLK+L5HRERENPkgBC8qtwPBEyruqFqfYo/4bISkINpUrUvoRBDYXim+YVfR1pKctulRBCxNapFDfgS3t6twY/I+HIDH2f9oewB1loA15veW1+F0IjQRERGRm00hCImAYan5iXS2Qkt0hjZDktmZ2uxALWuK7FRoysBoWjvmSzZvyaHYD0uDm8Fzm30l4/0eERER0ZSCkLXmRwYQa2doGVCMztRDGgbGCD2ZeBrOJJq3ksNpWw1QOpP9HhEREbnL1IKQDDjGbfRNaDtm7wydX1ZlNEcdeMJaUzR+iSClxsdrst8jIiIi95liEIrfRt+KAWdnaONZQxqCxyZ327wZpPzw2e4kC6GmNtEFO60xv8e7xoiIiEiZYhCKBw8NWkpn6Hx4iuTPdLfNj4Ps1NwXAOoLLf19/Ch+2NnXyGGy3yMiIiLXuUoX1GciIiIiV5lyjRARERHRQsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESu5d4gdCmK/ldD6P9NTE0gIiIit3FlEBruegBl3zqJyCfDOF61FDkbmqBdUTOJiIjINa7SBfXZJTQ0rNuJ8/va0eLLBy4F4buhBp82nkPn1/LUMkREROQGrqwRyrqiIfTvUXPkM2tQuhII9/ab40REROQaiyAIRdFaWYCbP5uDnBw1fPZmFBQsNT/fXIKyB5vR+7FaHB7s/8UIfvXdNebopV6EB4HyP1tvjhMREZFrLIIglIeqtnP4VV8Aq+TophZ89H9+hXPnPsLIyAhG+p5FUe8+3F1cg9Cw8QWb/qcOoKesBU/7stQUmnFDTSjJKUHTkBonIiKaI4unaay/D7Jxa9X6NbBFmuvXoHaHBxgOouFoRE00yU7TDww9il8cqRBxauaEai21VfFhXRPspSEiIqLZtmiCUG93p/gzD9478s0JFv39mvHzus8kI9Lw6Qb436nCT2QIurofHSdmOJZsbzdrqIzhDALwo5BhiIiIaE4tkiAUQc+bMSDry9j4BTUp7lIQx9vFz9wq1FWoep+zTXjoR2ux/xv5iEU1hF9oRGh4NpvG8lH3UgCewT6YEY2IiIjmwowGob179+LGG280Bvl5xkTDCA2Kn19aiyJziiEmpjeU16Dj1iocffswvJ+RU3vh3+BH8FkfCgsKUFBQgrKHgsDnZvnWeW0CIairxt6sVhtSM6QQahzzjKa4xDIRNK3LQU2XGlUih0oczXOO9eTUiCkWRhnEtHhZLN+1N/2l9v0xtmWdz/RHRETzxIwFIRl8nn/+eXzyySfGID/PWBh6J4yw+JH13nPYvPFu3L3xLhR8NgdL/+gpZD1xDh/94jDKP2cuCqxB4FfxJqrkcPgeNTuDtP184oMtmIyHCB2VQXgaHoVXTclIdiyuHECgL17WdlSoWWZ48WGg4UxiP87c5ofvmJo9AZFDbShObGME7duD8KU03YlpJyrNZd6ug2yElMfFB0uzX1sR/MXJMCRDUGF9Edrj80cC6Kv0syaMiIjmB/lAxZlwww036NnZ2bZBTpsJPfuWiPWv0A+8oyZIF0/q1UvEdv/iiH5BTZorp3bZj0N2drV+Ss0b0yvVGZc//8xqPXtto35ejccZ29sV/8Z5vXFttl79ihpVMn03wbldY3y13viBGpc+aNRXp5TN3N7qZ+SaT+nVYn+d2za/51gXERHRHFgEfYRU/yBsxFpr/6DcclT+pfjZ/TyO/9KcNKcSnaVljU4QPkctkr35yFLLtOlRBFaK5cW0kkP2+hntPQ2eHeVGzcx0sJWhMqimWhXBs1x9lIzmPbNsybIXwi+bKaUhDQNibys3qXEiIqJ5ZsaC0I4dO9SnpHTTpizeP2hTKeyPROxHz+vyZx6WXW9MmJLpaxrzoqUvAM8xv60vTf6e0yooqaE53miWj7q3zQBVVF9obM8ZiKbO7B9U+HIVzsS335ZsgBvVykDyO5bh9J7pimdEREQzZ8aC0NNPP41du3bh2muvNQb5WU6bdr1m/6CU5wdF+9FrvEUjF7lGJ+mp8TanXuwTQyK0jNPyOgS2a/DfO5Hb50WAEts60+CB9nJH4nvWz6YItAH10WLgbGptUkJXG4KoQLvq9zNunmJ4BlvRMeqDEYNoc3TUnlBHcSIiohk0o01jMvh8+OGHxjAjIUgIv57h+UHRCM6rj4ZLQez8civUG8bmnLe5HRWDfvjGqt3pqkm54yvO+7C8Bd++jsghX7JpypCP8h0iPNUfSN4FJtZp61AtAw0GoCUCjdmZe0zLy1G1MjXQhWrVHWdG4BNRqNJ6B9o4101ERDQLFmgfoSiCXy1AwdIclL0g+wdFcXDDzSjY2JSsaVi5DbVGn6EBhF8No/mvG5H/cNWMPkF6Yrx4VNbu1PvGfNVEsDLZDGc0X8VrbkTQON0XAFSTmRzkHVztInxY5e9pT/QzMpY7UWnULCWI9bQ3AP7i+HbaUDmupjHZbKceDhlftxj8tyXvhpM1acYdaIn5Yt2yaVDNJyIimktXyR7T6vPicyWG6Jlu9JyPIXeVF6XL3fE+scQt7RNtsiMiInKZRXDX2CiuzkLeF7wo31LumhBERERE47e4gxARERHRKBiEiIiIyLUWdx8hIiIiolGwRoiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0FowYugaV0OSg5F1Pg80lWDnJwcMZSgaUhNm6ihJpRM5fvzinmucmpDapyIiOYag9AkhWrlBT4HNV1qgk0INRnnuYQMMJUDCPSNYGTkNOqWq+lERETzCIPQFAUra0TsoRRaHzQUwePaAJSupi4fdW+LYNjsVeNERDTXFnQQGh4IoaNbQ+yKOR4b1hA+0YHQu9HEtBm1PYDAyiB8bOogIiJakGY0CO3duxc33nijMcjP0yn26gOo+cEwegIlKHgwiHCgDPfUhzGMTxH6rwVYurUVUbXszPGg7qUAPMd8YzSDyaay1H4uRvNaIkTFaxBCZj8So29NvHnNbGqzT0sVOVSSWCYnJ7Wmyj7fsZ54X5wu+TP995Ps5XH2ATL2qzIoPomQKOevaxJ7l8no60pS/WviyznDp1F+y3zHNuNNmeaQprxiffFlSg69laY2R7I3edrXaTmeRlkK4R8EtPpCtU65rvT9uZznxblv8fKNfn4dxyfjcSQiIht9hjz00EN6dna2bZDTpscF/bmv7NXf+J2un9ol132TXv3KRTVP188/s1pMq9ZPqfFMzO9mGHaN/m3ju2qZ1O2d0qvFOqpfUaPG+Gq98QM1qljXIdaiN66V204uZ6433TTrtuLfy9ZXP3NeTYvvW3I543trG8XSygeN+mprGdW4bZl01HLWbemvVBvbT+6vYEwb4xyMZ13xctmOn3l8k8fOebzFMdmV3A/7cRaMbSTXF/89sJY/5XgJtmmiXNUp5baW0Twvtn1LM815nuLLWLcdL1/ye2oZyz459/H8M9WWshARUSYzFoRuuOEG4x9v6yCnTYvLp/RH/r5HfHhff/KLYt1fOaInY5Cu9+xbIra3e/SL8BTZLzzOC9Pkg5D9wmmuJ90020XfcVE0WZcbx/ZV4LCGgXScF9y4lOnjCELjWlemclnXbyyTun8GY56zHPZjbWzPGQBT1pnu/FilPy/25R3TMpXbMT1t+WzHd6yyERFRJguzj1CWF4GGNUC0B91ngdKyjchVswANp7piwKZSrFdTZl7+OJvIJqfo1nz1KTPPbR71Kc6D4pXAwNkIMKRhQBwXf7G16SQHvmNq0QTxHedqbCLQBoCKLamdfb1bKsTGNFtz1Ogmsq405fIUi6lir2Tzz/I6BLar/XM2mRmdtlUTXWIwm61sijziLFqodbZ2qlIMdaB1sAKBPZalbM1xPrGVCZJlW1mFcmeH8uXlqFqpoU9T45KzfDbi9++xCtUMx877REQTMWNBaMeOHepTUrppU9IbRhh5WLMqT00QBo/j+C+B8ooyZKlJmTj7eNgG5wV1LOLC2d7gmcd3kVWgfUTeyu4YFskdTN5muT9nEBjwpZ6/lQGcSbPvp62hJg0ZyLSXO4xAFulshba9EvGjZfzuFLeiyng8gBzaxRGeQ5tajHKcaRhQoY+BiIhoPGYsCD399NPYtWsXrr32WmOQn+W06dTb3Sn+3Ii1XzDHJe3EcXHhKseXN4kY9PN9qDk6rOakMi+eGYZJBIT8Pe3qLjLNqI2xc/wPX9WIzBijBsODqjJxsV/uQRGCaJtybVU+PEVA8ETqJTZ0IjhGrYXT1NZlBJOU2hR1e3qbiCTH2swgIGuOBlvRMZmOw5sqUWF8N4KOlzVL7VUIbcdEtGyb4vORMpVNnbvRa+fSy99zWvz+ylA2HeebiGjxm9GmMRl8PvzwQ2OY7hAkg0X4dWcTWAQh2ZTh24aKz0TR+sQF/PmWZKPZzIs3kfkdTS9eVG4XF/3Hk3cyRQ75UptnpkA2iySb5SJoutdvCQpq+47aqsihmgnfWeR92GwCtN351FUD3zEPAg9PLDyOf12y2ctS9qEm+Oo1eHaUm2FJjNek3OGlqGYm/73Ou8jGU2PixaMNEL9HB9CKAB7dpCZbmx2VUK2zacwMetp7tvRrl2jSs5ZFnbvtgQmELPGd2tHuzCMiokwWZh8hKTaAfqN/0HpLE1g+1peJ/0b3Po+azT70/tWzIhCpWbNFNZE5eZvF/9IH/ShUTW8+tKNdhJPp4mloR/Hj5rqNPjDiwn3m7TozKAiy9qt9u72vTOF7lROv0RD7d7ovAKjbwo2hEmifzNOjx70uEYzaiuGPL1PsBxrO2Jq2BlLW0aKasWQt0RlxNJLHXg7+2x5NNHONJr+sCjgmIk48dBnMwGstd9uW1KaxeNCT81NvxTelnpdCtO44M/EayQHr/vmAthG0JIIbERFlcpXsMa0+Lzixj4eB63NT+gLFhqP49Oo85M52CCIiIqIFZUEHISIiIqKpWLhNY0RERERTxCBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSBERERErsUgRERERK7FIERERESuxSC0YEXQtC4HJYcianwe6apBTk6OGErQNKSmzbFQrShPbUiNqfF1TeIoEhGRmzEITVDkUIlxkU8fQOZxOJktQ00oqRxAoG8EIyOnUbdcTSciIpqHGIQmSav3zZvajnlF64OGInjmeQDyNoug9nYd8tX46EKoEeG3pkuNEhHRorGgg9DwQAgd3RpiV8zx2NkwOk6EoV0yx2fMygAC2zX472XTChER0UI2o0Fo7969uPHGG41Bfp5WP9+HnS8OQ3v2Liy9rwFN95Vhd9dHwKed+MbNd6HprFpuhpQ3t6Ni0A/fqM1gZlOZsybBaF6z9E+J918xfhp9a+LNa+b37dNSxZvrzKEGyZ4wimyuSswXg6WvjDmvBE1d8WXSfD/BXh45WPfNKH9lUHwKwifnZ+qDY/Qhktsxa1ri67LvX7yZMZTYZmJbo+2Pwb7e1PnJY26T6NukBll+Y5pP7JHYq0pzunWf7cdeDI51Os9tYh+d20pTRiIimgX6DHnooYf07Oxs2yCnTY8L+pHy+/Tjn+h6z74lYt136k++d1nN0/WTXxfb+4sjYqkMXqlOKVtyqNZPqcXSOf/Maj17baN+Xo4Y61mtN35gzBLO641rs/XVzxhzE+PVr6hRxbYO4dQuc9uJ5Szls09L3ZZcJrm9+Los+/BBo7463fd2qSWM+WLcUp70TunVcrn49yT1Xev2zXKOfgyT++csZ+qxs++zMNb+qHJay2Qcb0fZjeNkGTeXcax3V/yYmOt0nseUYx0vy2jnVkrZB7F+63ElIqJZM2NB6IYbbjAvPpZBTpseb+iP3H9Svxy/8NhCz2X9+Da5vd2WC9T0SRtiEuNmeSYVhGwXQrVfaaalBIWUC6j9oi3XbQsqkjWsqADiLKOTs8xxKdPHHYQcAUewryv9/o21P5nK6TzG9vH0QScpzfyUMKM4phvbcZZnPMeIiIhmxQLtI1SKwD+VI+tSL8KDgOeeUuSpOcAAel4XP27NH2dH2KnxjquJbHI8t3nUp8xSl/GgeKU4CmdleSLQBmTH7kJ7M4zRfGUlvjPGprT3NHh2lKcc0/yyKngGZQfpiUrtUJ1/axHgWJd9/8ben0zlHNWQJn5rKlC5SY2Ph+wUvrIK5c5O4cvLUbVSQ591J4o89vJsehSBlWbzoavvMCQimgdmLAjt2LFDfUpKN21K3gojJCJQ+XrLZebdUzgZA7K+VCou7xk4+2fYhtH6yKTjRUtbxby+i6yiTd7K7hxaRMkXpoW/P/moe1uWuR1FKtQxEBERzY0ZC0JPP/00du3ahWuvvdYY5Gc5bTr1v3VK/LkeawvNcUl75TiiWIX6+9eoKWlsanFcRK3DJC6oYn3txl1kHbKiI4VZO5Mkay1mzFAHWgc9qCqT4TAfHlGe4Impd8SVNTPayx0pnZ8jna3QVhZnDp0TEDoRBLZXjnL8x7c/qeU0a5IyWu4Rpy2ItoncHu8R+zzYig5n+FXHf6waNpMI0eJ37kxD+mNLREQzb0abxmTw+fDDD41hukOQvLh1d0XFz08x/Kk5BcNB+L8XwZrvvjDrD/KLN5H5j6kJhnyU7xAXufoDyVqmrhr4bMtMjWwmSt7FFEHTvX5bk413SwVwzGe/c22oCTUTrIHI3xMw9q/QeneTWI+vXkPFY+N9Ho9VED7rXWXquFRsGT2GjrU/3ocDIqDYmyojh3zwD6qRtLx4VISRYKX1SdjiWNbGy2dtblSW15mPUCi21iCq4789MPrvn9hXW/mJiGjOLNA+QoLqH5RfcgEHNvrwwIM+lNz+JJb98Bxe2z0d9RMTZTaROeXvaU/0BzGa3k5UGjUA08XT0I7ix+PNeoXwI4Az1gcFytovUa74rd/GUNyHyj0TjS6y9kKEPRFCkutpRVXfCFom0rcmoQLtj/WhML6uyqDR5DXmusbaHxFQTvcFAEs/Ih/a0b7dnJ1J/p7T4rxABJv4egvRelu8r1E+6h6TzZ/mOuMhRj6UsX275dzK7+w4g5HmsesUreUvfLnKfs6IiGjWXCV7TKvPC4vs51PZidpTH+GpLwwjOgzk5uUiS82mecw4d0D7Au6nREREi8OCrRHq7+0Wf5bBWyJ+ZOUijyGIiIiIJmgBBqEYhqNhHA9GgVv/ANd9PJx4xQYRERHRRCy8IBTtRnMgiOE/q0LVHVG0BloxEO8sTURERDQBC7ePEBEREdEULdy7xoiIiIimiEGIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhci0GIiIiIXItBiIiIiFyLQYiIiIhcCvj/lm81CsGYSb8AAAAASUVORK5CYII=)\n",
        "\n",
        "17. Why is MSE sensitive to outliers?\n",
        "Ans. MSE squares the errors, which amplifies the impact of large errors caused by outliers, making it unsuitable when outliers are present.\n",
        "\n",
        "18. What is the role of homoscedasticity in linear regression?\n",
        "Ans. Homoscedasticity ensures that residuals have constant variance. Violating this assumption leads to inefficient estimates and unreliable statistical tests.\n",
        "\n",
        "19. What is Root Mean Squared Error (RMSE)?\n",
        "Ans. RMSE is the square root of the average squared difference between predicted and actual values. It measures the typical error magnitude in the same unit as the dependent variable.\n",
        "\n",
        "20. Why is pickling considered risky?\n",
        "Ans. Pickling can execute arbitrary code during deserialization, making it vulnerable to malicious attacks if untrusted data is used.\n",
        "\n",
        "21. What alternatives exist to pickling for saving ML models?\n",
        "Ans. Joblib: Faster for large numpy arrays.\n",
        "ONNX: An open format for ML models.\n",
        "PMML: For sharing models across platforms.\n",
        "JSON: For storing lightweight models.\n",
        "\n",
        "22. What is heteroscedasticity, and why is it a problem?\n",
        "Ans. Heteroscedasticity occurs when residuals have non-constant variance. It leads to inefficient estimates, biased confidence intervals, and unreliable hypothesis tests.\n",
        "\n",
        "23. How can interaction terms enhance a regression model's predictive power?\n",
        "Ans. Interaction terms capture the combined effect of two or more predictors, allowing the model to account for non-linear relationships between variables."
      ],
      "metadata": {
        "id": "Avbfw9dazXIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Question:\n",
        "1. Visualize the distribution of errors (residuals) using Seaborn's \"diamonds\" dataset."
      ],
      "metadata": {
        "id": "ZsuDBxsq0aOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "\n",
        "# Select numeric columns for regression\n",
        "X = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]\n",
        "y = diamonds['price']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit linear regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Plot distribution of residuals\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title(\"Distribution of Residuals\")\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "782O57d45LiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Calculate and print MSE, MAE, and RMSE"
      ],
      "metadata": {
        "id": "RzVY39re5RTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "id": "aX3KN60Z5VP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Check assumptions of linear regression"
      ],
      "metadata": {
        "id": "2erQfiwa5Xor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linearity\n",
        "sns.pairplot(diamonds[['price', 'carat', 'depth', 'table']])\n",
        "plt.show()\n",
        "\n",
        "# Residuals plot for homoscedasticity\n",
        "sns.scatterplot(x=y_pred, y=residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title(\"Residuals vs. Predicted Values\")\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix for multicollinearity\n",
        "corr_matrix = X.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8oJfG8ox5aDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Create an ML pipeline with feature scaling and evaluate regression models"
      ],
      "metadata": {
        "id": "svgdrfdq5cNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "# Evaluate with cross-validation\n",
        "scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
        "print(f\"Linear Regression R-squared: {scores.mean():.4f}\")\n",
        "\n",
        "# Ridge Regression\n",
        "pipeline_ridge = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', Ridge())\n",
        "])\n",
        "ridge_scores = cross_val_score(pipeline_ridge, X, y, cv=5, scoring='r2')\n",
        "print(f\"Ridge Regression R-squared: {ridge_scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "id": "LxwUhY6d5exO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Simple Linear Regression with coefficients, intercept, and R-squared"
      ],
      "metadata": {
        "id": "K2UVO0oa5g-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Fit simple linear regression\n",
        "model.fit(X[['carat']], y)\n",
        "\n",
        "# Print coefficients and R-squared\n",
        "print(f\"Coefficient: {model.coef_[0]}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"R-squared: {r2_score(y, model.predict(X[['carat']]))}\")\n"
      ],
      "metadata": {
        "id": "3NuKORTk5j_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Analyze the relationship between total bill and tip (Seaborn \"tips\" dataset)"
      ],
      "metadata": {
        "id": "N70XC3jj5mNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tips dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Simple Linear Regression\n",
        "X = tips[['total_bill']]\n",
        "y = tips['tip']\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot regression line\n",
        "sns.regplot(x='total_bill', y='tip', data=tips, line_kws={'color': 'red'})\n",
        "plt.title(\"Total Bill vs. Tip\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LUpK9_nx5on6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Fit a linear regression model to synthetic data and plot"
      ],
      "metadata": {
        "id": "mI2xdP3Z5q60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot data and regression line\n",
        "plt.scatter(X, y, label=\"Data\")\n",
        "plt.plot(X, model.predict(X), color='red', label=\"Regression Line\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wLqFhZ_f5uIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Pickle a trained linear regression model"
      ],
      "metadata": {
        "id": "OnP76tsd5wU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save model\n",
        "with open('linear_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Load model\n",
        "with open('linear_model.pkl', 'rb') as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "AcbaHm8j5zVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Fit a polynomial regression model (degree 2) and plot"
      ],
      "metadata": {
        "id": "UDxVqQs-51au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Generate polynomial features\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Fit polynomial regression\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Plot regression curve\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, model.predict(X_poly), color='red')\n",
        "plt.title(\"Polynomial Regression (Degree 2)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LzMoztsP547E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Generate synthetic data for simple linear regression and fit a model"
      ],
      "metadata": {
        "id": "g9u4pAdY57ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print coefficients and intercept\n",
        "print(f\"Coefficient: {model.coef_[0]}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n"
      ],
      "metadata": {
        "id": "o8A8tyW65-3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Fit polynomial regression models of different degrees and compare performance"
      ],
      "metadata": {
        "id": "uFIUNDui6Awj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "degrees = [1, 2, 3, 4]\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "for degree in degrees:\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model.fit(X_poly, y)\n",
        "    score = cross_val_score(model,X_poly).sum()\n"
      ],
      "metadata": {
        "id": "y34DMi6i6Fih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Simple linear regression with two features"
      ],
      "metadata": {
        "id": "iq7TEBE06H20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data with two features\n",
        "X, y = make_regression(n_samples=100, n_features=2, noise=10, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print coefficients, intercept, and R-squared\n",
        "print(f\"Coefficients: {model.coef_}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"R-squared: {model.score(X, y)}\")\n"
      ],
      "metadata": {
        "id": "b3tZe5kP8cHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Generate synthetic data and visualize regression line"
      ],
      "metadata": {
        "id": "aW4A646A8euD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=15, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot data points and regression line\n",
        "plt.scatter(X, y, label=\"Data\")\n",
        "plt.plot(X, model.predict(X), color='red', label=\"Regression Line\")\n",
        "plt.legend()\n",
        "plt.title(\"Linear Regression on Synthetic Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nv2SPH1U8iNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Check for multicollinearity using VIF"
      ],
      "metadata": {
        "id": "pP1jf6E18thW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
        "\n",
        "# Calculate VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = data.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
        "\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "id": "2xd9raVp9Gh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Generate synthetic data for a degree-4 polynomial and fit a model"
      ],
      "metadata": {
        "id": "rTwqVXkK9Lex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "y = y**2  # Making the data polynomial\n",
        "\n",
        "# Fit polynomial regression\n",
        "poly = PolynomialFeatures(degree=4)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Plot regression curve\n",
        "plt.scatter(X, y, label=\"Data\")\n",
        "plt.plot(X, model.predict(X_poly), color='red', label=\"Polynomial Curve\")\n",
        "plt.legend()\n",
        "plt.title(\"Polynomial Regression (Degree 4)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c6QTLleD9OPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. ML pipeline with data standardization and multiple linear regression"
      ],
      "metadata": {
        "id": "M4fxcPSY9QZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit and evaluate pipeline\n",
        "pipeline.fit(X, y)\n",
        "r2_score = pipeline.score(X, y)\n",
        "print(f\"R-squared: {r2_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "k9207sC_9Vhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Polynomial regression (degree 3) on synthetic data"
      ],
      "metadata": {
        "id": "5HI3eMRz9Xy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "# Fit polynomial regression\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Plot regression curve\n",
        "plt.scatter(X, y, label=\"Data\")\n",
        "plt.plot(X, model.predict(X_poly), color='red', label=\"Polynomial Curve\")\n",
        "plt.legend()\n",
        "plt.title(\"Polynomial Regression (Degree 3)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wf_qCGEZ9aSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Multiple linear regression on synthetic data with 5 features"
      ],
      "metadata": {
        "id": "Lp9K9Dif9d5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data with 5 features\n",
        "X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print R-squared and coefficients\n",
        "print(f\"R-squared: {model.score(X, y):.4f}\")\n",
        "print(f\"Coefficients: {model.coef_}\")\n"
      ],
      "metadata": {
        "id": "JcXsNBEc9hj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Generate synthetic data, fit, and visualize regression line"
      ],
      "metadata": {
        "id": "tdfxqnDD9j00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot regression line\n",
        "plt.scatter(X, y, label=\"Data\")\n",
        "plt.plot(X, model.predict(X), color='red', label=\"Regression Line\")\n",
        "plt.legend()\n",
        "plt.title(\"Regression Line Visualization\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eXvzKslJ9rxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Multiple linear regression with 3 features"
      ],
      "metadata": {
        "id": "xvWrluKG9t63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data with 3 features\n",
        "X, y = make_regression(n_samples=100, n_features=3, noise=10, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print R-squared and coefficients\n",
        "print(f\"R-squared: {model.score(X, y):.4f}\")\n",
        "print(f\"Coefficients: {model.coef_}\")\n"
      ],
      "metadata": {
        "id": "kMEz4E5x9xCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Serialize and deserialize using joblib"
      ],
      "metadata": {
        "id": "1bF32hPI9zPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, 'linear_model.joblib')\n",
        "\n",
        "# Load model\n",
        "loaded_model = joblib.load('linear_model.joblib')\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "R9ZDi9fQ92CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Linear regression with categorical features using one-hot encoding"
      ],
      "metadata": {
        "id": "Eytxxfzw94iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load tips dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Separate features and target\n",
        "X = tips[['total_bill', 'sex', 'smoker', 'day']]\n",
        "y = tips['tip']\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[('encoder', OneHotEncoder(), ['sex', 'smoker', 'day'])],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_transformed = column_transformer.fit_transform(X)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_transformed, y)\n",
        "print(f\"R-squared: {model.score(X_transformed, y):.4f}\")\n"
      ],
      "metadata": {
        "id": "PWBDw7oX97-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Compare Ridge Regression with Linear Regression"
      ],
      "metadata": {
        "id": "1rskBYIp9_xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Fit Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X, y)\n",
        "\n",
        "# Compare R-squared and coefficients\n",
        "print(f\"Linear Regression R-squared: {model.score(X, y):.4f}\")\n",
        "print(f\"Ridge Regression R-squared: {ridge_model.score(X, y):.4f}\")\n",
        "print(f\"Linear Coefficients: {model.coef_}\")\n",
        "print(f\"Ridge Coefficients: {ridge_model.coef_}\")\n"
      ],
      "metadata": {
        "id": "ma8POh98-DPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Cross-validation for linear regression"
      ],
      "metadata": {
        "id": "A1UgkLrF-GyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "print(f\"Cross-validated R-squared: {scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "id": "vNXgEyNy-Iue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Compare polynomial regression models of different degrees"
      ],
      "metadata": {
        "id": "nWS9JRPq-Lph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for degree in range(1, 5):\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model.fit(X_poly, y)\n",
        "    score = model.score(X_poly, y)\n",
        "    print(f\"Degree {degree}: R-squared = {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "WP-Uscdb-PzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}